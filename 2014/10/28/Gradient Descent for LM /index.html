
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  
    <title>单变量线性回归 - 梯度下降算法 | WackyYang`s Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=3, minimum-scale=1">
    
    <meta name="author" content="WackyYoung">
    
    <meta name="description" content="本文主要涉及机器学习单变量线性回归，讲述单变量成本函数(Cost Function)和单变量梯度下降函数(Gradient Descent Function),R语言的实现方法。
  试验的数据集来及NG机器学习课程。
  单变量线性回归简介：
方法论：线性回归属于监督学习，因此方法和监督学习应该是">
    
    
    
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/pacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/pacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css" type="text/css">

</head>

  <body>
    <header>
      <div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.svg" alt="WackyYang`s Blog" title="WackyYang`s Blog"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="WackyYang`s Blog">WackyYang`s Blog</a></h1>
				<h2 class="blog-motto">如果我不曾见过太阳，我本可以忍受黑暗</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">主页</a></li>
					
						<li><a href="/archives">存档</a></li>
					
						<li><a href="/categories">分类</a></li>
					
						<li><a href="/about">关于</a></li>
					
					<li>
					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="text" id="search" name="q" autocomplete="off" maxlength="20" placeholder="搜索" />
						<input type="hidden" name="q" value="site:yoursite.com">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>

    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2014/10/28/Gradient Descent for LM /" title="单变量线性回归 - 梯度下降算法" itemprop="url">单变量线性回归 - 梯度下降算法</a>
  </h1>
  <p class="article-author">By
    
      <a href="http://yoursite.com" title="WackyYoung">WackyYoung</a>
    </p>
  <p class="article-time">
    <time datetime="2014-10-28T12:31:24.000Z" itemprop="datePublished">2014-10-28</time>
    更新日期:<time datetime="2014-10-28T12:31:02.000Z" itemprop="dateModified">2014-10-28</time>
    
  </p>
</header>
	<div class="article-content">
		
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">文章目录</strong>
		<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#对于线性模型，更为通用的写法为："><span class="toc-number">1.</span> <span class="toc-text">对于线性模型，更为通用的写法为：</span></a></li></ol>
		</div>
		
		<p>  本文主要涉及机器学习单变量线性回归，讲述单变量成本函数(Cost Function)和单变量梯度下降函数(Gradient Descent Function),R语言的实现方法。</p>
<p>  试验的数据集来及NG机器学习课程。</p>
<p>  单变量线性回归简介：</p>
<p>方法论：线性回归属于监督学习，因此方法和监督学习应该是一样的，先给定一个训练集，根据这个训练集学习出一个线性函数，然后测试这个函数训练的好不好（即此函数是否足够拟合训练集数据），挑选出最好的函数（cost function最小）即可。</p>
<p>注意：<br>(1)因为是线性回归，所以学习到的函数为线性函数，即直线函数；<br>(2)因为是单变量，因此只有一个x；</p>
<p>从上面“方法”中，我们肯定有一个疑问，怎么样能够看出线性函数拟合的好不好呢？我们需要使用到Cost Function（成本函数），成本函数越小，说明线性回归地越好（和训练集拟合地越好），当然最小就是0，即完全拟合；</p>
<p>基于这次测试的过程：</p>
<p>1.数据集准备</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">setwd(<span class="string">'D:/OneDrive/Document/Open Class/Coursear/机器学习/斯坦福/编程练习/mlclass-ex1-007/mlclass-ex1-007/mlclass-ex1'</span>)</div><div class="line">data = read.table(<span class="string">"./ex1data1.txt"</span>,sep=<span class="string">','</span>)</div></pre></td></tr></table></figure>

<p>2.数据整理</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">X = data[<span class="number">2</span>]</div><div class="line">y = as.matrix(data[<span class="number">1</span>])</div><div class="line">m = length(y)</div><div class="line">x0 = matrix(<span class="number">1</span>,nrow=m)</div><div class="line">X$x0 = x0</div><div class="line">X$x1 = as.matrix(data[<span class="number">1</span>])</div><div class="line">X = X[<span class="number">2</span>:<span class="number">3</span>]</div><div class="line">head(X)    <span class="comment">## 输入</span></div></pre></td></tr></table></figure>



<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="preprocessor">##   x0    V1</span></div><div class="line"><span class="preprocessor">## 1  1 6.110</span></div><div class="line"><span class="preprocessor">## 2  1 5.528</span></div><div class="line"><span class="preprocessor">## 3  1 8.519</span></div><div class="line"><span class="preprocessor">## 4  1 7.003</span></div><div class="line"><span class="preprocessor">## 5  1 5.860</span></div><div class="line"><span class="preprocessor">## 6  1 8.383</span></div></pre></td></tr></table></figure>



<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">head(y)    <span class="comment">## 输出</span></div></pre></td></tr></table></figure>



<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="preprocessor">##         V1</span></div><div class="line"><span class="preprocessor">## [1,] 6.110</span></div><div class="line"><span class="preprocessor">## [2,] 5.528</span></div><div class="line"><span class="preprocessor">## [3,] 8.519</span></div><div class="line"><span class="preprocessor">## [4,] 7.003</span></div><div class="line"><span class="preprocessor">## [5,] 5.860</span></div><div class="line"><span class="preprocessor">## [6,] 8.383</span></div></pre></td></tr></table></figure>



<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">m          <span class="comment">## 样本数量</span></div></pre></td></tr></table></figure>



<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="preprocessor">## [1] 97</span></div></pre></td></tr></table></figure>



<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">rm(x0)</div></pre></td></tr></table></figure>

<ol>
<li>数据集点图及lm线性拟合</li>
</ol>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">## Plotting the Data</span></div><div class="line"><span class="keyword">library</span>(ggplot2)</div><div class="line">colnames(data)&lt;-c(<span class="string">'Profit'</span>,<span class="string">'Population'</span>)</div><div class="line">p = ggplot(data,aes(Population,Profit))</div><div class="line">p= p + geom_point(colour = <span class="string">"red"</span>, size = <span class="number">4</span>)+ </div><div class="line">    xlab(<span class="string">'Population of City in 10,000s'</span>)+</div><div class="line">    ylab(<span class="string">'Profit in $10,000s'</span>)</div><div class="line">coef(lm(Population ~ Profit, data = data))</div></pre></td></tr></table></figure>



<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="preprocessor">## (Intercept)      Profit </span></div><div class="line"><span class="preprocessor">##      -3.896       1.193</span></div></pre></td></tr></table></figure>



<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">p + stat_smooth(method=<span class="string">"lm"</span>, se=<span class="literal">FALSE</span>, size= <span class="number">1</span>)</div></pre></td></tr></table></figure>

<p><img src="figure/unnamed-chunk-3.png" alt="plot of chunk unnamed-chunk-3"> </p>
<p>1.假设为线性模型，则那么hypotheses定义为：</p>
<p><img src="http://www.52ml.net/images/88f558cc854ba27a87d153b85be17e11.png" alt="">，<img src="http://www.52ml.net/images/9defe8d8425370f18780cd9456bd2234.png" alt=""></p>
<h2 id="对于线性模型，更为通用的写法为：">对于线性模型，更为通用的写法为：</h2>
<p><img src="http://www.52ml.net/images/ce91b7bb3677bb2e0c9b26c5bc3a9b96.png" alt=""></p>
<p>其中把θ和X看成向量，并且x0=1，就可以表示成最后那种，两个向量相乘的形式</p>
<p>2.线性回归的目的，就是通过训练集找出使得误差最小的一组参数θ（称为学习） 为了可以量化误差，定义损失函数（cost function）：</p>
<p><img src="http://www.52ml.net/images/2a2a3bfc106e3cd1fa3359671ca31a30.png" alt=""></p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">## Gradient Descent init</span></div><div class="line">theta = matrix(<span class="number">0</span>,nrow=<span class="number">2</span>)  <span class="comment">## 初始化θ</span></div><div class="line">X = as.matrix(X)</div><div class="line">iterations = <span class="number">150</span>          <span class="comment">## 步长</span></div><div class="line">alpha = <span class="number">0.0005</span>            <span class="comment">## 学习速率</span></div><div class="line"></div><div class="line"><span class="comment">## cost_function of J_theta</span></div><div class="line">J_theta = <span class="keyword">function</span>(X,y,m,theta){</div><div class="line">    J_theta = <span class="number">1</span>/(<span class="number">2</span>*m)*sum(((X%*%theta)-y)^<span class="number">2</span>)</div><div class="line">    <span class="keyword">return</span>(J_theta)</div><div class="line">}</div><div class="line">J_theta(X,y,m,theta)</div></pre></td></tr></table></figure>



<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="preprocessor">## [1] 40.7</span></div></pre></td></tr></table></figure>

<p>3.利用梯度下降算法计算出J(θ)的最小值。</p>
<p>先随意选取初始θ，比如θ=0，然后不断的以梯度的方向修正θ，最终使J(θ)收敛到最小 。当然梯度下降找到的最优是局部最优，也就是说选取不同的初值，可能会找到不同的局部最优点 但是对于最小二乘的损失函数模型，比较简单只有一个最优点，所以局部最优即全局最优。</p>
<p>对于某个参数的梯度，其实就是J(θ)对该参数求导的结果，所以对于某个参数每次调整的公式如下：</p>
<p><img src="http://www.52ml.net/images/d1552da01c81dc48e48c18b93ce7192a.png" alt=""></p>
<p>α - 学习速率。代表下降幅度，步长，小会导致收敛慢，大会导致错过最优点</p>
<p>当实际训练集中会有m个样本点，所以最终公式为：</p>
<p><img src="http://www.52ml.net/images/7c7361009cbf2495af97e56478d1b1ef.png" alt=""></p>
<p>算法实现如下：</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">## Gradient Descent Function</span></div><div class="line">Gradient_Descent = <span class="keyword">function</span>(X, y, theta, alpha,num_iters){</div><div class="line">    J_history = matrix(<span class="number">0</span>,ncol=<span class="number">1</span>,nrow=num_iters)</div><div class="line">    <span class="keyword">for</span> (i <span class="keyword">in</span> <span class="number">1</span>:m){</div><div class="line">        p = theta[<span class="number">1</span>] - alpha*(<span class="number">1</span>/m)*sum(((X%*%theta)-y))*X[i, <span class="number">1</span>];</div><div class="line">        q = theta[<span class="number">2</span>] - alpha*(<span class="number">1</span>/m)*sum(((X%*%theta)-y))*X[i, <span class="number">2</span>];</div><div class="line">        theta[<span class="number">1</span>] = p ;</div><div class="line">        theta[<span class="number">2</span>] = q ;</div><div class="line">        J_history[i] = J_theta(X,y,m,theta);</div><div class="line">    } </div><div class="line">    print(theta);  </div><div class="line">    <span class="keyword">return</span>(J_history);   </div><div class="line">}</div><div class="line">J_history = Gradient_Descent(X, y, theta, alpha,iterations)</div></pre></td></tr></table></figure>



<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="preprocessor">##        [,1]</span></div><div class="line"><span class="preprocessor">## [1,] 0.1183</span></div><div class="line"><span class="preprocessor">## [2,] 0.9503</span></div></pre></td></tr></table></figure>



<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">## 收敛到min时的θ值</span></div><div class="line">df = data.frame(x=c(<span class="number">1</span>:length(J_history)),y=J_history)</div><div class="line">ggplot(data=df,aes(x,y))+</div><div class="line">    geom_point(colour=<span class="string">'red'</span>,size=<span class="number">2</span>)+</div><div class="line">    stat_smooth(size=<span class="number">1</span>)+</div><div class="line">    xlab(<span class="string">' Number of iterations '</span>)+</div><div class="line">    ylab(<span class="string">' Cost of J'</span>)</div></pre></td></tr></table></figure>



<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">## geom_smooth: <span class="function"><span class="keyword">method</span>="<span class="title">auto</span>" <span class="title">and</span> <span class="title">size</span> <span class="title">of</span> <span class="title">largest</span> <span class="title">group</span> <span class="title">is</span> &lt;1000, <span class="title">so</span> <span class="title">using</span> <span class="title">loess</span>. <span class="title">Use</span> '<span class="title">method</span> = <span class="title">x</span>' <span class="title">to</span> <span class="title">change</span> <span class="title">the</span> <span class="title">smoothing</span> <span class="title">method</span>.</span></div></pre></td></tr></table></figure>

<p><img src="figure/unnamed-chunk-5.png" alt="plot of chunk unnamed-chunk-5"> </p>
  
	</div>
		<footer class="article-footer clearfix">

  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>


<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/数据科学/">数据科学</a>
</div>



<div class="article-share" id="share">

  <div data-url="http://yoursite.com/2014/10/28/Gradient Descent for LM /" data-title="单变量线性回归 - 梯度下降算法 | WackyYang`s Blog" data-tsina="2255106785" class="share clearfix">
  </div>

</div>
</footer>   	       
	</article>
	
<nav class="article-nav clearfix">
 

<div class="next">
<a href="/2014/10/27/R语言矩阵运算/"  title="R语言矩阵运算">
 <strong>NEXT:</strong><br/> 
 <span>R语言矩阵运算
</span>
</a>
</div>

</nav>

	
<section class="comment">
	<div class="ds-thread"></div>
</section>

</div>  
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">文章目录</strong>
  <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#对于线性模型，更为通用的写法为："><span class="toc-number">1.</span> <span class="toc-text">对于线性模型，更为通用的写法为：</span></a></li></ol>
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  
<div class="categorieslist">
	<p class="asidetitle">分类</p>
		<ul>
		
			<li><a href="/categories/English-Learning/" title="English Learning">English Learning<sup>2</sup></a></li>
		
			<li><a href="/categories/数据科学/" title="数据科学">数据科学<sup>3</sup></a></li>
		
			<li><a href="/categories/生活/" title="生活">生活<sup>1</sup></a></li>
		
		</ul>
</div>


  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			<li><a href="/tags/Fundamental-English-Writing/" title="Fundamental English Writing">Fundamental English Writing<sup>2</sup></a></li>
		
			<li><a href="/tags/R-Language/" title="R Language">R Language<sup>1</sup></a></li>
		
			<li><a href="/tags/homework/" title="homework">homework<sup>1</sup></a></li>
		
			<li><a href="/tags/机器学习/" title="机器学习">机器学习<sup>1</sup></a></li>
		
		</ul>
</div>


  <div class="rsspart">
	<a href="null" target="_blank" title="rss">RSS 订阅</a>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Going in one more round when you don&#39;t think you can <br/>
			that&#39;s what makes all difference in your life.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		<a href="http://weibo.com/2255106785" target="_blank" title="weibo"></a>
		
		
		
		<a href="https://github.com/Wackyyang" target="_blank" title="github"></a>
		
		
	</div>
		<p class="copyright">Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/A-limon/pacman" target="_blank" title="Pacman">Pacman</a> © 2014 
		
		<a href="http://yoursite.com" target="_blank" title="WackyYoung">WackyYoung</a>
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.1.0.min.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else
    {
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      h  = $('article h2')
      ah = $('article h2'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  if(ah.length==0){
    t.css('display','none');
  }else{
    c.click(function(){
      ta.css('display', 'block').addClass('fadeIn');
    });
    o.click(function(){
      ta.css('display', 'none');
    });
    $(window).scroll(function(){
      ta.css("top",Math.max(140,320-$(this).scrollTop()));
    });
  };
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina');
  var html = [
  '<a href="#" class="overlay" id="qrcode"></a>',
  '<div class="qrcode clearfix"><span>扫描二维码分享到微信朋友圈</span><a class="qrclose" href="#share"></a><strong>Loading...Please wait</strong><img id="qrcode-pic" data-src="http://s.jiathis.com/qrcode.php?url=' + encodedUrl + '"/></div>',
  '<a href="#textlogo" class="article-back-to-top" title="Top"></a>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="QRcode"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="Weibo"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);
  $('.article-share-qrcode').click(function(){
    var imgSrc = $('#qrcode-pic').attr('data-src');
    $('#qrcode-pic').attr('src', imgSrc);
    $('#qrcode-pic').load(function(){
        $('.qrcode strong').text(' ');
    });
  });
});     
</script>


<script type="text/javascript">
  var duoshuoQuery = {short_name:"null"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
    || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script> 





  </body>
</html>
